vocab_size: 69
block_size: 256
n_layer: 2
n_head: 4
n_embd: 128
dropout: 0.1
batch_size: 2
grad_accum_steps: 16
lr: 0.0003
weight_decay: 0.05
max_steps: 2000
epochs: 5
warmup_steps: 200
out_dir: outputs/checkpoints_tiny
seed: 1337

